# -*- coding: utf-8 -*-
"""END2END model attention.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W67oLt25DdFIjQ4Li4ljnFmiNfoVri_I
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data as utils
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch.optim as optim
from torch.autograd import Variable
from torch.nn.parameter import Parameter
import time
import torchvision.models as models

import math
from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer

device = None
if torch.cuda.is_available():
  device = torch.device('cuda')
else:
  device = torch.device('cpu')

torch.manual_seed(0)
np.random.seed(0)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

file_inputs_P = np.load('/content/drive/MyDrive/DL Dataset/Graph_Classification/Paldi_features_X.npy')
file_labels_P = np.load('/content/drive/MyDrive/DL Dataset/Graph_Classification/Paldi_labels_y.npy')
print(file_inputs_P.shape, file_labels_P.shape)

file_inputs_N = np.load('/content/drive/MyDrive/DL Dataset/Graph_Classification/Nehru_features_X.npy')
file_labels_N = np.load('/content/drive/MyDrive/DL Dataset/Graph_Classification/Nehru_labels_y.npy')
print(file_inputs_N.shape, file_labels_N.shape)

file_inputs_A = np.load('/content/drive/MyDrive/DL Dataset/Graph_Classification/APMC_features_X.npy')
file_labels_A = np.load('/content/drive/MyDrive/DL Dataset/Graph_Classification/APMC_features_y.npy')
file_inputs_A = file_inputs_A.astype('float64')
print(file_inputs_A.shape, file_labels_A.shape)

def convert_to_seqlabels(file_inputs, file_labels, seq_len = 5, pred_len = 10):
  input_sequence = []
  input_target_sequence = []
  target_sequence = []
  labels = []

  for idx, input in enumerate(file_inputs):
    input_len = input.shape[0]
    for i in range(input_len - seq_len - pred_len+1):
      input_sequence.append(input[i : i + seq_len, : ])
      input_target_sequence.append(input[i + seq_len - 1 : i + seq_len + pred_len - 1])
      target_sequence.append(input[i + seq_len : i + seq_len + pred_len])
      labels.append(file_labels[idx])

  input_sequence = np.asarray(input_sequence)
  input_target_sequence = np.asarray(input_target_sequence)
  target_sequence = np.asarray(target_sequence)
  labels = np.asarray(labels)

  return input_sequence, input_target_sequence, target_sequence, labels

def TFPrepareDataset(file_inputs_P, file_labels_P, file_inputs_N, file_labels_N, file_inputs_A, file_labels_A, seq_len = 15, pred_len = 25, BATCH_SIZE = 32,
                     train_ratio = 0.7, valid_ratio = 0.1):

  input_sequence_P, input_target_sequence_P, target_sequence_P, labels_P = convert_to_seqlabels(file_inputs_P, file_labels_P, seq_len, pred_len)
  input_sequence_N, input_target_sequence_N, target_sequence_N, labels_N = convert_to_seqlabels(file_inputs_N, file_labels_N, seq_len, pred_len)
  input_sequence_A, input_target_sequence_A, target_sequence_A, labels_A = convert_to_seqlabels(file_inputs_A, file_labels_A, seq_len, pred_len)

  train_index_P = int(np.floor(len(input_sequence_P) * train_ratio))
  valid_index_P = int(np.floor(len(input_sequence_P) * (valid_ratio + train_ratio)))
  train_index_N = int(np.floor(len(input_sequence_N) * train_ratio))
  valid_index_N = int(np.floor(len(input_sequence_N) * (valid_ratio + train_ratio)))
  train_index_A = int(np.floor(len(input_sequence_A) * train_ratio))
  valid_index_A = int(np.floor(len(input_sequence_A) * (valid_ratio + train_ratio)))


  train_input_P, train_target_P = torch.tensor(input_sequence_P[:train_index_P]), torch.tensor(target_sequence_P[:train_index_P])
  train_input_target_P, train_labels_P = torch.tensor(input_target_sequence_P[:train_index_P]), torch.tensor(labels_P[:train_index_P])
  valid_input_P, valid_target_P = torch.tensor(input_sequence_P[train_index_P:valid_index_P]), torch.tensor(target_sequence_P[train_index_P:valid_index_P])
  valid_input_target_P, valid_labels_P = torch.tensor(input_target_sequence_P[train_index_P:valid_index_P]), torch.tensor(labels_P[train_index_P:valid_index_P])
  test_input_P, test_target_P = torch.tensor(input_sequence_P[valid_index_P:]), torch.tensor(target_sequence_P[valid_index_P:])
  test_input_target_P, test_labels_P = torch.tensor(input_target_sequence_P[valid_index_P:]), torch.tensor(labels_P[valid_index_P:])

  train_input_N, train_target_N = torch.tensor(input_sequence_N[:train_index_N]), torch.tensor(target_sequence_N[:train_index_N])
  train_input_target_N, train_labels_N = torch.tensor(input_target_sequence_N[:train_index_N]), torch.tensor(labels_N[:train_index_N])
  valid_input_N, valid_target_N = torch.tensor(input_sequence_N[train_index_N:valid_index_N]), torch.tensor(target_sequence_N[train_index_N:valid_index_N])
  valid_input_target_N, valid_labels_N = torch.tensor(input_target_sequence_N[train_index_N:valid_index_N]), torch.tensor(labels_N[train_index_N:valid_index_N])
  test_input_N, test_target_N = torch.tensor(input_sequence_N[valid_index_N:]), torch.tensor(target_sequence_N[valid_index_N:])
  test_input_target_N, test_labels_N = torch.tensor(input_target_sequence_N[valid_index_N:]), torch.tensor(labels_N[valid_index_N:])

  train_input_A, train_target_A = torch.tensor(input_sequence_A[:train_index_A]), torch.tensor(target_sequence_A[:train_index_A])
  train_input_target_A, train_labels_A = torch.tensor(input_target_sequence_A[:train_index_A]), torch.tensor(labels_A[:train_index_A])
  valid_input_A, valid_target_A = torch.tensor(input_sequence_A[train_index_A:valid_index_A]), torch.tensor(target_sequence_A[train_index_A:valid_index_A])
  valid_input_target_A, valid_labels_A = torch.tensor(input_target_sequence_A[train_index_A:valid_index_A]), torch.tensor(labels_A[train_index_A:valid_index_A])
  test_input_A, test_target_A = torch.tensor(input_sequence_A[valid_index_A:]), torch.tensor(target_sequence_A[valid_index_A:])
  test_input_target_A, test_labels_A = torch.tensor(input_target_sequence_A[valid_index_A:]), torch.tensor(labels_A[valid_index_A:])

  train_input = torch.cat((train_input_P, train_input_N, train_input_A), dim=0)
  train_input_target = torch.cat((train_input_target_P, train_input_target_N, train_input_target_A), dim=0)
  train_target = torch.cat((train_target_P, train_target_N, train_target_A), dim=0)
  train_labels = torch.cat((train_labels_P, train_labels_N, train_labels_A), dim=0)
  print("Train shapes: ", train_input.shape, train_input_target.shape, train_target.shape, train_labels.shape)
  valid_input = torch.cat((valid_input_P, valid_input_N, valid_input_A), dim=0)
  valid_input_target = torch.cat((valid_input_target_P, valid_input_target_N, valid_input_target_A), dim=0)
  valid_target = torch.cat((valid_target_P, valid_target_N, valid_target_A), dim=0)
  valid_labels = torch.cat((valid_labels_P, valid_labels_N, valid_labels_A), dim=0)
  print("Valid shapes: ", valid_input.shape, valid_input_target.shape, valid_target.shape, valid_labels.shape)
  test_input = torch.cat((test_input_P, test_input_N, test_input_A), dim=0)
  test_input_target = torch.cat((test_input_target_P, test_input_target_N, test_input_target_A), dim=0)
  test_target = torch.cat((test_target_P, test_target_N, test_target_A), dim=0)
  test_labels = torch.cat((test_labels_P, test_labels_N, test_labels_A), dim=0)
  print("Test shapes: ", test_input.shape, test_input_target.shape, test_target.shape, test_labels.shape)

  train_dataset = utils.TensorDataset(train_input, train_input_target, train_target, train_labels)
  valid_dataset = utils.TensorDataset(valid_input, valid_input_target, valid_target, valid_labels)
  test_dataset = utils.TensorDataset(test_input, test_input_target, test_target, test_labels)

  train_dataloader = utils.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last=False)
  valid_dataloader = utils.DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last=False)
  test_dataloader = utils.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last=False)

  return train_dataloader, valid_dataloader, test_dataloader

train_dataloader, valid_dataloader, test_dataloader = TFPrepareDataset(file_inputs_P, file_labels_P, file_inputs_N, file_labels_N, file_inputs_A, file_labels_A)

input, input_target_seq, target_seq, labels = next(iter(train_dataloader))
[batch_size, seq_len, fea_size] = input.size()
[batch_size, pred_len, fea_size] = target_seq.size()
print("Batch Size: ", batch_size)
print("Seq len: ", seq_len)
print("Prediction len: ", pred_len)
print("Input Target Seq Size: ", input_target_seq.shape)
print("Labels Size: ", labels.shape)

print(len(train_dataloader))
print(len(valid_dataloader))
print(len(test_dataloader))

def check(labels, state):
  total = 0
  cnt = 0

  for (i,j) in zip(labels, state):
    if j.argmax() == i:
      cnt+=1
    total+=1

  return cnt/total

def TrainModel(model, train_dataloader, valid_dataloader, epochs, learning_rate=1e-3, train_force=1, c_weight=0.5, p_weight=0.5):

  model = model.train()
  model = model.to(device)

  optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)
  loss_func_class = nn.CrossEntropyLoss()
  loss_func_pred = nn.MSELoss()

  curr = time.time()
  prev = time.time()

  for epoch in range(epochs):

    train_loss_c = []
    train_loss_p = []
    train_loss_t = []
    train_acc = []

    for data in train_dataloader:
      input, input_target_seq, target_seq, labels = data
      input, input_target_seq, target_seq, labels = input.to(device), input_target_seq.to(device), target_seq.to(device), labels.to(device)

      optimizer.zero_grad()
      model.zero_grad()

      if train_force == 1:
        out, state = model(input.double(), input_target_seq.double())
      else:
        out, state = model(input.double(), input_target_seq[:,0:1,:].double(), 0, pred_len)

      loss_c = loss_func_class(state, labels)
      loss_p = loss_func_pred(out, target_seq)
      total_loss = loss_c * c_weight + loss_p * p_weight

      train_loss_c.append(loss_c.data)
      train_loss_p.append(loss_p.data)
      train_loss_t.append(total_loss.data)
      train_acc.append(check(labels, state))

      total_loss.backward()
      optimizer.step()

    valid_loss_p = []
    valid_loss_c = []
    valid_loss_t = []
    valid_acc = []

    for data in valid_dataloader:
      input, input_target_seq, target_seq, labels = data
      input, input_target_seq, target_seq, labels = input.to(device), input_target_seq.to(device), target_seq.to(device), labels.to(device)

      if train_force == 1:
        out, state = model(input.double(), input_target_seq.double())
      else:
        out, state = model(input.double(), input_target_seq[:,0:1,:].double(), 0, pred_len)

      loss_c = loss_func_class(state, labels)
      loss_p = loss_func_pred(out, target_seq)

      total_loss = loss_c * c_weight + loss_p * p_weight

      valid_loss_c.append(loss_c.data)
      valid_loss_p.append(loss_p.data)
      valid_loss_t.append(total_loss.data)
      valid_acc.append(check(labels, state))

    avg_p_train = sum(train_loss_p) / len(train_loss_p)
    avg_c_train = sum(train_loss_c) / len(train_loss_c)
    avg_t_train = sum(train_loss_t) / len(train_loss_t)
    avg_acc_train = sum(train_acc) / len(train_acc)

    avg_p_valid = sum(valid_loss_p) / len(valid_loss_p)
    avg_c_valid = sum(valid_loss_c) / len(valid_loss_c)
    avg_t_valid = sum(valid_loss_t) / len(valid_loss_t)
    avg_acc_valid = sum(valid_acc) / len(valid_acc)
    curr = time.time()

    print(f"Epoch: {epoch} Time: {curr-prev :.4f}")
    print(f"Train T Loss: {avg_t_train :.4f} Train Acc: {avg_acc_train :.4f} Valid T Loss: {avg_t_valid :.4f} Valid Acc: {avg_acc_valid :.4f} ")
    print(f"Train C Loss: {avg_c_train :.4f} Train P Loss: {avg_p_train :.4f} Valid C Loss: {avg_c_valid :.4f} Valid P Loss: {avg_p_valid :.4f}")
    print("")

    prev = curr

  return model

def TestModel(model, test_dataloader, test_force = True, c_weight=0.5, p_weight=0.5):

  model = model.eval()

  loss_func_class = nn.CrossEntropyLoss()
  loss_func_pred = nn.MSELoss()

  test_loss_c = []
  test_loss_p = []
  test_loss_t = []
  test_acc = []
  pred = []
  pred_probs = []
  true = []

  for data in test_dataloader:
    input, input_target_seq, target_seq, labels = data
    input, input_target_seq, target_seq, labels = input.to(device), input_target_seq.to(device), target_seq.to(device), labels.to(device)

    if test_force == True:
      out, state = model(input.double(), input_target_seq.double())
    else:
      out, state = model(input.double(), input_target_seq[:,0:1,:].double(), 0, pred_len)

    loss_p = loss_func_pred(out, target_seq)
    loss_c = loss_func_class(state, labels)

    total_loss = loss_p * p_weight + loss_c * c_weight

    test_loss_c.append(loss_c.data)
    test_loss_p.append(loss_p.data)
    test_loss_t.append(total_loss.data)
    test_acc.append(check(labels, state))

    pred_probs.extend(state.cpu().data.numpy())
    for x in state:
      pred.append(x.argmax().cpu().data.numpy())
    for x in labels:
      true.append(x.cpu().data.numpy())

  avg_p = sum(test_loss_p) / len(test_loss_p)
  avg_c = sum(test_loss_c) / len(test_loss_c)
  avg_t = sum(test_loss_t) / len(test_loss_t)
  avg_acc = sum(test_acc) / len(test_acc)

  print(f"P Loss: {avg_p :.4f} C Loss: {avg_c :.4f} T Loss: {avg_t :.4f} Acc: {avg_acc :.4f}")
  return pred, true, pred_probs

class PositionalEncoding(nn.Module):

    def __init__(self, d_model, dropout=0.1, max_len=5000):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(p=dropout)

        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)[:,:-1]
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)

    def forward(self, x):
        x = x + self.pe[:x.size(0), :]
        return self.dropout(x)

class TransformerEncoderDecoder(nn.Module):

  def __init__(self, d_model = 147, nheads = 3, num_layers = 2):

    super(TransformerEncoderDecoder, self).__init__()
    encoder_layer = nn.TransformerEncoderLayer(d_model, nheads)
    self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)
    self.postional_encode = PositionalEncoding(d_model)
    decoder_layer = nn.TransformerDecoderLayer(d_model, nheads)
    self.decoder = nn.TransformerDecoder(decoder_layer, num_layers)
    self.encoder_mask = None
    self.decoder_mask = None
    self.d_model = d_model

  def generate_mask(self, src_len):
    mask = (torch.triu(torch.ones(src_len,src_len)) == 1).transpose(0,1)
    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))

    return mask

  def forward(self, input, target, is_train = 1, pred_length = 2):

    input = input.permute(1, 0, 2)
    target = target.permute(1, 0, 2)

    if self.encoder_mask is None or self.encoder_mask.size(0) != len(input):
      mask = self.generate_mask(len(input)).to(device)
      self.encoder_mask = mask

    if self.decoder_mask is None or self.decoder_mask.size(0) != len(target):
      mask = self.generate_mask(len(target)).to(device)
      self.decoder_mask = mask

    src = self.postional_encode(input)
    encoder_out = self.encoder(src, self.encoder_mask)

    if is_train == 1:
      decoder_out = self.decoder(target, encoder_out, self.decoder_mask)
      return decoder_out.permute(1,0,2)

    else:
      outputs = None
      for i in range(pred_length):
        decoder_out = self.decoder(target, encoder_out, self.decoder_mask)
        if outputs is None:
            outputs = decoder_out
        else:
            outputs = torch.cat((outputs, decoder_out), 0)
        target = decoder_out
      return outputs.permute(1,0,2)

class Attention(nn.Module):
  def __init__(self, hidden_size=100):
    super(Attention, self).__init__()
    self.attn_combine = nn.Linear(hidden_size+hidden_size, hidden_size)

  def forward(self, decoder_hidden, encoder_out):
    attn_weights = F.softmax(torch.bmm(decoder_hidden, encoder_out.permute(0,2,1)), dim=2)
    c = torch.bmm(attn_weights, encoder_out)
    concat_c = torch.cat((c,decoder_hidden), dim=2)
    attn_h = self.attn_combine(concat_c)

    return attn_h

class End2End(nn.Module):

  def __init__(self, d_model = 147, nheads = 3, num_layers = 2):
    super(End2End, self).__init__()
    self.encoder_decoder = TransformerEncoderDecoder(d_model, nheads, num_layers)
    self.gru1 = nn.GRU(d_model, 100, batch_first=True) #gru
    self.gru2 = nn.GRU(100, 50, batch_first=True)  #gru
    #self.lstm1 = nn.LSTM(d_model, 100, batch_first=True) #lstm
    #self.lstm2 = nn.LSTM(100, 50, batch_first=True) #lstm
    #self.rnn1 = nn.RNN(d_model, 100, batch_first=True) #rnn
    #self.rnn2 = nn.RNN(100, 50, batch_first=True) #rnn
    self.attention = Attention()
    self.dropout = nn.Dropout(0.4)
    self.fc = nn.Linear(50, 3)

  def forward(self, input, input_target_seq, is_train=1, pred_len=25):
    out = self.encoder_decoder(input, input_target_seq, is_train, pred_len)
    #state, (hidden, _) = self.lstm1(out)  #lstm
    #state, hidden = self.rnn1(out)  #rnn
    state, hidden = self.gru1(out)  #GRU
    state = self.attention(hidden.permute(1,0,2), state) #attention
    #_, (state, _) = self.lstm2(hidden.permute(1,0,2))    #lstm
    #_, state = self.rnn2(state)  #rnn
    _, state = self.gru2(state)   #gru
    state = self.fc(state.squeeze(dim=0))

    return out, state

model = End2End().double().to(device)

# X = torch.randn((32,10,147)).to(device)
# X_tar = torch.randn((32,25,147)).to(device)

# out, state = model(X.double(), X_tar.double())
# print(out.shape, state.shape)

model.load_state_dict(torch.load('/content/drive/MyDrive/Pre-Trained Weights/IITH-END2END-N-I15P25-59.18.pt'))

model = TrainModel(model, train_dataloader, valid_dataloader, 10, learning_rate=6e-4, train_force=1, c_weight=1, p_weight=0.55)

model = TrainModel(model, train_dataloader, valid_dataloader, 20, learning_rate=1e-4, train_force=0, c_weight=1, p_weight=0.55)

pred, true = TestModel(model, test_dataloader, test_force=False, c_weight=1, p_weight=0.55)

pred, true = TestModel(model, train_dataloader, test_force=False, c_weight=1, p_weight=0.55)

pred, true = TestModel(model, valid_dataloader, test_force=False, c_weight=1, p_weight=0.55)

pred, true, probs = TestModel(model, test_dataloader, test_force=False, c_weight=1, p_weight=0.55)

print(np.array(pred).shape, np.array(true).shape, np.array(probs).shape)

true_probs = []
cnt=0;
for i in true:
  cnt+=1
  #print(i)
  true_probs.append(np.eye(3)[i])
print(cnt)
np.array(true_probs).shape

from sklearn.metrics import precision_recall_curve
from sklearn.metrics import average_precision_score

true_probs = np.array(true_probs)
probs = np.array(probs)

# For each class
precision = dict()
recall = dict()
average_precision = dict()
for i in range(3):
    precision[i], recall[i], _ = precision_recall_curve(true_probs[:, i],
                                                        probs[:, i])
    average_precision[i] = average_precision_score(true_probs[:, i], probs[:, i])

# A "micro-average": quantifying score on all classes jointly
precision["micro"], recall["micro"], _ = precision_recall_curve(true_probs.ravel(),
    probs.ravel())
average_precision["micro"] = average_precision_score(true_probs, probs,
                                                     average="micro")
print('Average precision score, micro-averaged over all classes: {0:0.2f}'
      .format(average_precision["micro"]))

plt.step(recall['micro'], precision['micro'], where='post')

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([0.0, 1.05])
plt.xlim([0.0, 1.0])
plt.title(
    'Average precision score, micro-averaged over all classes: AP={0:0.2f}'
    .format(average_precision["micro"]))

precision = dict()
recall = dict()
for i in range(3):
    precision[i], recall[i], _ = precision_recall_curve(true_probs[:, i],
                                                        probs[:, i])
    plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))

plt.xlabel("recall")
plt.ylabel("precision")
plt.legend(loc="best")
plt.title("precision vs. recall curve")
plt.show()

from sklearn.metrics import precision_recall_curve, roc_curve
from sklearn.preprocessing import label_binarize

# roc curve
fpr = dict()
tpr = dict()

for i in range(3):
    fpr[i], tpr[i], _ = roc_curve(true_probs[:, i],
                                  probs[:, i])
    plt.plot(fpr[i], tpr[i], lw=2, label='class {}'.format(i))

plt.xlabel("false positive rate")
plt.ylabel("true positive rate")
plt.legend(loc="best")
plt.title("ROC curve")
plt.show()

from sklearn.metrics import confusion_matrix

c_m = confusion_matrix(true, pred)
print("Actual Accuracy: ", c_m.trace()/c_m.sum())  #Actual output

c_m

#torch.save(model.state_dict(), '/content/drive/My Drive/Pre-Trained Weights/IITH-END2END-I15P25-SavedData-57.94.pt')

#torch.save(model.state_dict(), '/content/drive/My Drive/Pre-Trained Weights/IITH-END2END-I10P25-NOExtra-57.92.pt')

#from mlxtend.plotting import plot_confusion_matrix

# fig, ax = plot_confusion_matrix(conf_mat=c_m,
#                                 show_absolute=True,
#                                 show_normed=True,
#                                 colorbar=False)
# plt.show()



#model.load_state_dict(torch.load('/content/drive/My Drive/Pre-Trained Weights/IITH-END2END-I15P25-C1P0.55-64.19.pt'))

