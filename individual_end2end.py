# -*- coding: utf-8 -*-
"""Individual End2End.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LcsploxxJ8E6u6cWsM3Iq5QK3DcsoCgh

Paldi Dataset
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data as utils
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch.optim as optim
from torch.autograd import Variable
from torch.nn.parameter import Parameter
import time
import torchvision.models as models

import math
from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer

device = None
if torch.cuda.is_available():
  device = torch.device('cuda')
else:
  device = torch.device('cpu')

torch.manual_seed(0)
np.random.seed(0)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

file_inputs_P = np.load('/content/drive/My Drive/Graph_Classification/Paldi_features_X.npy')
file_labels_P = np.load('/content/drive/My Drive/Graph_Classification/Paldi_labels_y.npy')
print(file_inputs_P.shape, file_labels_P.shape)

def convert_to_seqlabels(file_inputs, file_labels, seq_len = 5, pred_len = 10):
  input_sequence = []
  input_target_sequence = []
  target_sequence = []
  labels = []

  for idx, input in enumerate(file_inputs):
    input_len = input.shape[0]
    for i in range(input_len - seq_len - pred_len+1):
      input_sequence.append(input[i : i + seq_len, : ])
      input_target_sequence.append(input[i + seq_len - 1 : i + seq_len + pred_len - 1])
      target_sequence.append(input[i + seq_len : i + seq_len + pred_len])
      labels.append(file_labels[idx])

  input_sequence = np.asarray(input_sequence)
  input_target_sequence = np.asarray(input_target_sequence)
  target_sequence = np.asarray(target_sequence)
  labels = np.asarray(labels)

  return input_sequence, input_target_sequence, target_sequence, labels

def TFPrepareDataset(file_inputs_P, file_labels_P, seq_len = 15, pred_len = 25, BATCH_SIZE = 32, train_ratio = 0.7, valid_ratio = 0.1):

  input_sequence_P, input_target_sequence_P, target_sequence_P, labels_P = convert_to_seqlabels(file_inputs_P, file_labels_P, seq_len, pred_len)

  train_index_P = int(np.floor(len(input_sequence_P) * train_ratio))
  valid_index_P = int(np.floor(len(input_sequence_P) * (valid_ratio + train_ratio)))

  train_input_P, train_target_P = torch.tensor(input_sequence_P[:train_index_P]), torch.tensor(target_sequence_P[:train_index_P])
  train_input_target_P, train_labels_P = torch.tensor(input_target_sequence_P[:train_index_P]), torch.tensor(labels_P[:train_index_P])
  valid_input_P, valid_target_P = torch.tensor(input_sequence_P[train_index_P:valid_index_P]), torch.tensor(target_sequence_P[train_index_P:valid_index_P])
  valid_input_target_P, valid_labels_P = torch.tensor(input_target_sequence_P[train_index_P:valid_index_P]), torch.tensor(labels_P[train_index_P:valid_index_P])
  test_input_P, test_target_P = torch.tensor(input_sequence_P[valid_index_P:]), torch.tensor(target_sequence_P[valid_index_P:])
  test_input_target_P, test_labels_P = torch.tensor(input_target_sequence_P[valid_index_P:]), torch.tensor(labels_P[valid_index_P:])

  print("Train shapes: ", train_input_P.shape, train_input_target_P.shape, train_target_P.shape, train_labels_P.shape)
  print("Valid shapes: ", valid_input_P.shape, valid_input_target_P.shape, valid_target_P.shape, valid_labels_P.shape)
  print("Test shapes: ", test_input_P.shape, test_input_target_P.shape, test_target_P.shape, test_labels_P.shape)

  train_dataset = utils.TensorDataset(train_input_P, train_input_target_P, train_target_P, train_labels_P)
  valid_dataset = utils.TensorDataset(valid_input_P, valid_input_target_P, valid_target_P, valid_labels_P)
  test_dataset = utils.TensorDataset(test_input_P, test_input_target_P, test_target_P, test_labels_P)

  train_dataloader = utils.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last=False)
  valid_dataloader = utils.DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last=False)
  test_dataloader = utils.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last=False)

  return train_dataloader, valid_dataloader, test_dataloader

train_dataloader, valid_dataloader, test_dataloader = TFPrepareDataset(file_inputs_P, file_labels_P)

input, input_target_seq, target_seq, labels = next(iter(train_dataloader))
[batch_size, seq_len, fea_size] = input.size()
[batch_size, pred_len, fea_size] = target_seq.size()
print("Batch Size: ", batch_size)
print("Seq len: ", seq_len)
print("Prediction len: ", pred_len)
print("Input Target Seq Size: ", input_target_seq.shape)
print("Labels Size: ", labels.shape)

print(len(train_dataloader))
print(len(valid_dataloader))
print(len(test_dataloader))

def check(labels, state):
  total = 0
  cnt = 0

  for (i,j) in zip(labels, state):
    if j.argmax() == i:
      cnt+=1
    total+=1

  return cnt/total

def TrainModel(model, train_dataloader, valid_dataloader, epochs, learning_rate=1e-3, train_force=1, c_weight=0.5, p_weight=0.5):

  model = model.train()
  model = model.to(device)

  optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)
  loss_func_class = nn.CrossEntropyLoss()
  loss_func_pred = nn.MSELoss()

  curr = time.time()
  prev = time.time()

  for epoch in range(epochs):

    train_loss_c = []
    train_loss_p = []
    train_loss_t = []
    train_acc = []

    for data in train_dataloader:
      input, input_target_seq, target_seq, labels = data
      input, input_target_seq, target_seq, labels = input.to(device), input_target_seq.to(device), target_seq.to(device), labels.to(device)

      optimizer.zero_grad()
      model.zero_grad()

      if train_force == 1:
        out, state = model(input.double(), input_target_seq.double())
      else:
        out, state = model(input.double(), input_target_seq[:,0:1,:].double(), 0, pred_len)

      loss_c = loss_func_class(state, labels)
      loss_p = loss_func_pred(out, target_seq)
      total_loss = loss_c * c_weight + loss_p * p_weight

      train_loss_c.append(loss_c.data)
      train_loss_p.append(loss_p.data)
      train_loss_t.append(total_loss.data)
      train_acc.append(check(labels, state))

      total_loss.backward()
      optimizer.step()

    valid_loss_p = []
    valid_loss_c = []
    valid_loss_t = []
    valid_acc = []

    for data in valid_dataloader:
      input, input_target_seq, target_seq, labels = data
      input, input_target_seq, target_seq, labels = input.to(device), input_target_seq.to(device), target_seq.to(device), labels.to(device)

      if train_force == 1:
        out, state = model(input.double(), input_target_seq.double())
      else:
        out, state = model(input.double(), input_target_seq[:,0:1,:].double(), 0, pred_len)

      loss_c = loss_func_class(state, labels)
      loss_p = loss_func_pred(out, target_seq)

      total_loss = loss_c * c_weight + loss_p * p_weight

      valid_loss_c.append(loss_c.data)
      valid_loss_p.append(loss_p.data)
      valid_loss_t.append(total_loss.data)
      valid_acc.append(check(labels, state))

    avg_p_train = sum(train_loss_p) / len(train_loss_p)
    avg_c_train = sum(train_loss_c) / len(train_loss_c)
    avg_t_train = sum(train_loss_t) / len(train_loss_t)
    avg_acc_train = sum(train_acc) / len(train_acc)

    avg_p_valid = sum(valid_loss_p) / len(valid_loss_p)
    avg_c_valid = sum(valid_loss_c) / len(valid_loss_c)
    avg_t_valid = sum(valid_loss_t) / len(valid_loss_t)
    avg_acc_valid = sum(valid_acc) / len(valid_acc)
    curr = time.time()

    print(f"Epoch: {epoch} Time: {curr-prev :.4f}")
    print(f"Train T Loss: {avg_t_train :.4f} Train Acc: {avg_acc_train :.4f} Valid T Loss: {avg_t_valid :.4f} Valid Acc: {avg_acc_valid :.4f} ")
    print(f"Train C Loss: {avg_c_train :.4f} Train P Loss: {avg_p_train :.4f} Valid C Loss: {avg_c_valid :.4f} Valid P Loss: {avg_p_valid :.4f}")
    print("")

    prev = curr

  return model

def TestModel(model, test_dataloader, test_force = True, c_weight=0.5, p_weight=0.5):

  model = model.eval()

  loss_func_class = nn.CrossEntropyLoss()
  loss_func_pred = nn.MSELoss()

  test_loss_c = []
  test_loss_p = []
  test_loss_t = []
  test_acc = []
  pred = []
  true = []

  for i, data in enumerate(test_dataloader):
    input, input_target_seq, target_seq, labels = data
    input, input_target_seq, target_seq, labels = input.to(device), input_target_seq.to(device), target_seq.to(device), labels.to(device)

    if test_force == True:
      out, state = model(input.double(), input_target_seq.double())
    else:
      out, state = model(input.double(), input_target_seq[:,0:1,:].double(), 0, pred_len)

    loss_p = loss_func_pred(out, target_seq)
    loss_c = loss_func_class(state, labels)

    total_loss = loss_p * p_weight + loss_c * c_weight

    test_loss_c.append(loss_c.data)
    test_loss_p.append(loss_p.data)
    test_loss_t.append(total_loss.data)
    test_acc.append(check(labels, state))

    for x in state:
      pred.append(x.argmax().cpu().data.numpy())
    for x in labels:
      true.append(x.cpu().data.numpy())

  avg_p = sum(test_loss_p) / len(test_loss_p)
  avg_c = sum(test_loss_c) / len(test_loss_c)
  avg_t = sum(test_loss_t) / len(test_loss_t)
  avg_acc = sum(test_acc) / len(test_acc)

  print(f"P Loss: {avg_p :.4f} C Loss: {avg_c :.4f} T Loss: {avg_t :.4f} Acc: {avg_acc :.4f}")
  return pred, true

class PositionalEncoding(nn.Module):

    def __init__(self, d_model, dropout=0.1, max_len=5000):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(p=dropout)

        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)[:,:-1]
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)

    def forward(self, x):
        x = x + self.pe[:x.size(0), :]
        return self.dropout(x)

class TransformerEncoderDecoder(nn.Module):

  def __init__(self, d_model = 147, nheads = 3, num_layers = 2):

    super(TransformerEncoderDecoder, self).__init__()
    encoder_layer = nn.TransformerEncoderLayer(d_model, nheads)
    self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)
    self.postional_encode = PositionalEncoding(d_model)
    decoder_layer = nn.TransformerDecoderLayer(d_model, nheads)
    self.decoder = nn.TransformerDecoder(decoder_layer, num_layers)
    self.encoder_mask = None
    self.decoder_mask = None
    self.d_model = d_model

  def generate_mask(self, src_len):
    mask = (torch.triu(torch.ones(src_len,src_len)) == 1).transpose(0,1)
    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))

    return mask

  def forward(self, input, target, is_train = 1, pred_length = 2):

    input = input.permute(1, 0, 2)
    target = target.permute(1, 0, 2)

    if self.encoder_mask is None or self.encoder_mask.size(0) != len(input):
      mask = self.generate_mask(len(input)).to(device)
      self.encoder_mask = mask

    if self.decoder_mask is None or self.decoder_mask.size(0) != len(target):
      mask = self.generate_mask(len(target)).to(device)
      self.decoder_mask = mask

    src = self.postional_encode(input)
    encoder_out = self.encoder(src, self.encoder_mask)

    if is_train == 1:
      decoder_out = self.decoder(target, encoder_out, self.decoder_mask)
      return decoder_out.permute(1,0,2)

    else:
      outputs = None
      for i in range(pred_length):
        decoder_out = self.decoder(target, encoder_out, self.decoder_mask)
        if outputs is None:
            outputs = decoder_out
        else:
            outputs = torch.cat((outputs, decoder_out), 0)
        target = decoder_out
      return outputs.permute(1,0,2)

class Attention(nn.Module):
  def __init__(self, hidden_size=100):
    super(Attention, self).__init__()
    self.attn_combine = nn.Linear(hidden_size+hidden_size, hidden_size)

  def forward(self, decoder_hidden, encoder_out):
    attn_weights = F.softmax(torch.bmm(decoder_hidden, encoder_out.permute(0,2,1)), dim=2)
    c = torch.bmm(attn_weights, encoder_out)
    concat_c = torch.cat((c,decoder_hidden), dim=2)
    attn_h = self.attn_combine(concat_c)

    return attn_h

class End2End(nn.Module):

  def __init__(self, d_model = 147, nheads = 3, num_layers = 2):
    super(End2End, self).__init__()
    self.encoder_decoder = TransformerEncoderDecoder(d_model, nheads, num_layers)
    self.gru1 = nn.GRU(d_model, 100, batch_first=True)
    self.gru2 = nn.GRU(100, 50, batch_first=True)
    self.attention = Attention()
    self.dropout = nn.Dropout(0.4)
    self.fc = nn.Linear(50, 3)

  def forward(self, input, input_target_seq, is_train=1, pred_len=25):
    out = self.encoder_decoder(input, input_target_seq, is_train, pred_len)
    state, hidden = self.gru1(out)
    state = self.attention(hidden.permute(1,0,2), state)
    _, state = self.gru2(state)
    state = F.softmax(self.fc(state.squeeze(dim=0)), dim=1)

    return out, state

model = End2End().double().to(device)

# X = torch.randn((1,10,147)).to(device)
# X_tar = torch.randn((1,15,147)).to(device)

# out, state = model(X.double(), X_tar.double())
# print(out.shape, state.shape)

#model = TrainModel(model, train_dataloader, valid_dataloader, 10, learning_rate=6e-4, train_force=1, c_weight=1, p_weight=0.55)

#model = TrainModel(model, train_dataloader, valid_dataloader, 20, learning_rate=1e-4, train_force=0, c_weight=1, p_weight=0.55)

model.load_state_dict(torch.load('/content/drive/My Drive/Pre-Trained Weights/IITH-END2END-APMC-C1P0.55.pt'))

pred, true = TestModel(model, test_dataloader, test_force=False, c_weight=1, p_weight=0.55)

from sklearn.metrics import confusion_matrix

c_m = confusion_matrix(true, pred)
print("Actual Accuracy: ", c_m.trace()/c_m.sum())

from mlxtend.plotting import plot_confusion_matrix

fig, ax = plot_confusion_matrix(conf_mat=c_m,
                                show_absolute=True,
                                show_normed=True,
                                colorbar=True)
plt.show()

import seaborn as sns

df_cm = pd.DataFrame(c_m, index = ['N','C','U'],
                  columns = ['N','C','U'])
sns.set(font_scale=1.0)
plt.figure(figsize = (6,6))
sns.heatmap(df_cm, annot=True, cbar = False, annot_kws={"size": 30}, cmap = 'Greens', linecolor='black', linewidths=0.05, fmt='.0f')

PATH = '/content/drive/My Drive/Pre-Trained Weights/IITH-END2END-P-C1P0.55.pt'
torch.save(model.state_dict(), PATH)

"""Nehru Dataset"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data as utils
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch.optim as optim
from torch.autograd import Variable
from torch.nn.parameter import Parameter
import time
import torchvision.models as models

import math
from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer

device = None
if torch.cuda.is_available():
  device = torch.device('cuda')
else:
  device = torch.device('cpu')

torch.manual_seed(0)
np.random.seed(0)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

file_inputs_N = np.load('/content/drive/My Drive/Graph_Classification/Nehru_features_X.npy')
file_labels_N = np.load('/content/drive/My Drive/Graph_Classification/Nehru_labels_y.npy')
print(file_inputs_N.shape, file_labels_N.shape)

def convert_to_seqlabels(file_inputs, file_labels, seq_len = 5, pred_len = 10):
  input_sequence = []
  input_target_sequence = []
  target_sequence = []
  labels = []

  for idx, input in enumerate(file_inputs):
    input_len = input.shape[0]
    for i in range(input_len - seq_len - pred_len+1):
      input_sequence.append(input[i : i + seq_len, : ])
      input_target_sequence.append(input[i + seq_len - 1 : i + seq_len + pred_len - 1])
      target_sequence.append(input[i + seq_len : i + seq_len + pred_len])
      labels.append(file_labels[idx])

  input_sequence = np.asarray(input_sequence)
  input_target_sequence = np.asarray(input_target_sequence)
  target_sequence = np.asarray(target_sequence)
  labels = np.asarray(labels)

  return input_sequence, input_target_sequence, target_sequence, labels

def TFPrepareDataset(file_inputs_N, file_labels_N, seq_len = 15, pred_len = 25, BATCH_SIZE = 32, train_ratio = 0.7, valid_ratio = 0.1):

  input_sequence_N, input_target_sequence_N, target_sequence_N, labels_N = convert_to_seqlabels(file_inputs_N, file_labels_N, seq_len, pred_len)

  train_index_N = int(np.floor(len(input_sequence_N) * train_ratio))
  valid_index_N = int(np.floor(len(input_sequence_N) * (valid_ratio + train_ratio)))

  train_input_N, train_target_N = torch.tensor(input_sequence_N[:train_index_N]), torch.tensor(target_sequence_N[:train_index_N])
  train_input_target_N, train_labels_N = torch.tensor(input_target_sequence_N[:train_index_N]), torch.tensor(labels_N[:train_index_N])
  valid_input_N, valid_target_N = torch.tensor(input_sequence_N[train_index_N:valid_index_N]), torch.tensor(target_sequence_N[train_index_N:valid_index_N])
  valid_input_target_N, valid_labels_N = torch.tensor(input_target_sequence_N[train_index_N:valid_index_N]), torch.tensor(labels_N[train_index_N:valid_index_N])
  test_input_N, test_target_N = torch.tensor(input_sequence_N[valid_index_N:]), torch.tensor(target_sequence_N[valid_index_N:])
  test_input_target_N, test_labels_N = torch.tensor(input_target_sequence_N[valid_index_N:]), torch.tensor(labels_N[valid_index_N:])

  print("Train shapes: ", train_input_N.shape, train_input_target_N.shape, train_target_N.shape, train_labels_N.shape)
  print("Valid shapes: ", valid_input_N.shape, valid_input_target_N.shape, valid_target_N.shape, valid_labels_N.shape)
  print("Test shapes: ", test_input_N.shape, test_input_target_N.shape, test_target_N.shape, test_labels_N.shape)

  train_dataset = utils.TensorDataset(train_input_N, train_input_target_N, train_target_N, train_labels_N)
  valid_dataset = utils.TensorDataset(valid_input_N, valid_input_target_N, valid_target_N, valid_labels_N)
  test_dataset = utils.TensorDataset(test_input_N, test_input_target_N, test_target_N, test_labels_N)

  train_dataloader = utils.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last=False)
  valid_dataloader = utils.DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last=False)
  test_dataloader = utils.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last=False)

  return train_dataloader, valid_dataloader, test_dataloader

train_dataloader, valid_dataloader, test_dataloader = TFPrepareDataset(file_inputs_N, file_labels_N)

input, input_target_seq, target_seq, labels = next(iter(train_dataloader))
[batch_size, seq_len, fea_size] = input.size()
[batch_size, pred_len, fea_size] = target_seq.size()
print("Batch Size: ", batch_size)
print("Seq len: ", seq_len)
print("Prediction len: ", pred_len)
print("Input Target Seq Size: ", input_target_seq.shape)
print("Labels Size: ", labels.shape)

print(len(train_dataloader))
print(len(valid_dataloader))
print(len(test_dataloader))

def check(labels, state):
  total = 0
  cnt = 0

  for (i,j) in zip(labels, state):
    if j.argmax() == i:
      cnt+=1
    total+=1

  return cnt/total

def TrainModel(model, train_dataloader, valid_dataloader, epochs, learning_rate=1e-3, train_force=1, c_weight=0.5, p_weight=0.5):

  model = model.train()
  model = model.to(device)

  optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)
  loss_func_class = nn.CrossEntropyLoss()
  loss_func_pred = nn.MSELoss()

  curr = time.time()
  prev = time.time()

  for epoch in range(epochs):

    train_loss_c = []
    train_loss_p = []
    train_loss_t = []
    train_acc = []

    for data in train_dataloader:
      input, input_target_seq, target_seq, labels = data
      input, input_target_seq, target_seq, labels = input.to(device), input_target_seq.to(device), target_seq.to(device), labels.to(device)

      optimizer.zero_grad()
      model.zero_grad()

      if train_force == 1:
        out, state = model(input.double(), input_target_seq.double())
      else:
        out, state = model(input.double(), input_target_seq[:,0:1,:].double(), 0, pred_len)

      loss_c = loss_func_class(state, labels)
      loss_p = loss_func_pred(out, target_seq)
      total_loss = loss_c * c_weight + loss_p * p_weight

      train_loss_c.append(loss_c.data)
      train_loss_p.append(loss_p.data)
      train_loss_t.append(total_loss.data)
      train_acc.append(check(labels, state))

      total_loss.backward()
      optimizer.step()

    valid_loss_p = []
    valid_loss_c = []
    valid_loss_t = []
    valid_acc = []

    for data in valid_dataloader:
      input, input_target_seq, target_seq, labels = data
      input, input_target_seq, target_seq, labels = input.to(device), input_target_seq.to(device), target_seq.to(device), labels.to(device)

      if train_force == 1:
        out, state = model(input.double(), input_target_seq.double())
      else:
        out, state = model(input.double(), input_target_seq[:,0:1,:].double(), 0, pred_len)

      loss_c = loss_func_class(state, labels)
      loss_p = loss_func_pred(out, target_seq)

      total_loss = loss_c * c_weight + loss_p * p_weight

      valid_loss_c.append(loss_c.data)
      valid_loss_p.append(loss_p.data)
      valid_loss_t.append(total_loss.data)
      valid_acc.append(check(labels, state))

    avg_p_train = sum(train_loss_p) / len(train_loss_p)
    avg_c_train = sum(train_loss_c) / len(train_loss_c)
    avg_t_train = sum(train_loss_t) / len(train_loss_t)
    avg_acc_train = sum(train_acc) / len(train_acc)

    avg_p_valid = sum(valid_loss_p) / len(valid_loss_p)
    avg_c_valid = sum(valid_loss_c) / len(valid_loss_c)
    avg_t_valid = sum(valid_loss_t) / len(valid_loss_t)
    avg_acc_valid = sum(valid_acc) / len(valid_acc)
    curr = time.time()

    print(f"Epoch: {epoch} Time: {curr-prev :.4f}")
    print(f"Train T Loss: {avg_t_train :.4f} Train Acc: {avg_acc_train :.4f} Valid T Loss: {avg_t_valid :.4f} Valid Acc: {avg_acc_valid :.4f} ")
    print(f"Train C Loss: {avg_c_train :.4f} Train P Loss: {avg_p_train :.4f} Valid C Loss: {avg_c_valid :.4f} Valid P Loss: {avg_p_valid :.4f}")
    print("")

    prev = curr

  return model

def TestModel(model, test_dataloader, test_force = True, c_weight=0.5, p_weight=0.5):

  model = model.eval()

  loss_func_class = nn.CrossEntropyLoss()
  loss_func_pred = nn.MSELoss()

  test_loss_c = []
  test_loss_p = []
  test_loss_t = []
  test_acc = []
  pred = []
  true = []

  for data in test_dataloader:
    input, input_target_seq, target_seq, labels = data
    input, input_target_seq, target_seq, labels = input.to(device), input_target_seq.to(device), target_seq.to(device), labels.to(device)

    if test_force == True:
      out, state = model(input.double(), input_target_seq.double())
    else:
      out, state = model(input.double(), input_target_seq[:,0:1,:].double(), 0, pred_len)

    loss_p = loss_func_pred(out, target_seq)
    loss_c = loss_func_class(state, labels)

    total_loss = loss_p * p_weight + loss_c * c_weight

    test_loss_c.append(loss_c.data)
    test_loss_p.append(loss_p.data)
    test_loss_t.append(total_loss.data)
    test_acc.append(check(labels, state))

    for x in state:
      pred.append(x.argmax().cpu().data.numpy())
    for x in labels:
      true.append(x.cpu().data.numpy())

  avg_p = sum(test_loss_p) / len(test_loss_p)
  avg_c = sum(test_loss_c) / len(test_loss_c)
  avg_t = sum(test_loss_t) / len(test_loss_t)
  avg_acc = sum(test_acc) / len(test_acc)

  print(f"P Loss: {avg_p :.4f} C Loss: {avg_c :.4f} T Loss: {avg_t :.4f} Acc: {avg_acc :.4f}")
  return pred, true

class PositionalEncoding(nn.Module):

    def __init__(self, d_model, dropout=0.1, max_len=5000):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(p=dropout)

        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)[:,:-1]
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)

    def forward(self, x):
        x = x + self.pe[:x.size(0), :]
        return self.dropout(x)

class TransformerEncoderDecoder(nn.Module):

  def __init__(self, d_model = 147, nheads = 3, num_layers = 2):

    super(TransformerEncoderDecoder, self).__init__()
    encoder_layer = nn.TransformerEncoderLayer(d_model, nheads)
    self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)
    self.postional_encode = PositionalEncoding(d_model)
    decoder_layer = nn.TransformerDecoderLayer(d_model, nheads)
    self.decoder = nn.TransformerDecoder(decoder_layer, num_layers)
    self.encoder_mask = None
    self.decoder_mask = None
    self.d_model = d_model

  def generate_mask(self, src_len):
    mask = (torch.triu(torch.ones(src_len,src_len)) == 1).transpose(0,1)
    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))

    return mask

  def forward(self, input, target, is_train = 1, pred_length = 2):

    input = input.permute(1, 0, 2)
    target = target.permute(1, 0, 2)

    if self.encoder_mask is None or self.encoder_mask.size(0) != len(input):
      mask = self.generate_mask(len(input)).to(device)
      self.encoder_mask = mask

    if self.decoder_mask is None or self.decoder_mask.size(0) != len(target):
      mask = self.generate_mask(len(target)).to(device)
      self.decoder_mask = mask

    src = self.postional_encode(input)
    encoder_out = self.encoder(src, self.encoder_mask)

    if is_train == 1:
      decoder_out = self.decoder(target, encoder_out, self.decoder_mask)
      return decoder_out.permute(1,0,2)

    else:
      outputs = None
      for i in range(pred_length):
        decoder_out = self.decoder(target, encoder_out, self.decoder_mask)
        if outputs is None:
            outputs = decoder_out
        else:
            outputs = torch.cat((outputs, decoder_out), 0)
        target = decoder_out
      return outputs.permute(1,0,2)

class Attention(nn.Module):
  def __init__(self, hidden_size=100):
    super(Attention, self).__init__()
    self.attn_combine = nn.Linear(hidden_size+hidden_size, hidden_size)

  def forward(self, decoder_hidden, encoder_out):
    attn_weights = F.softmax(torch.bmm(decoder_hidden, encoder_out.permute(0,2,1)), dim=2)
    c = torch.bmm(attn_weights, encoder_out)
    concat_c = torch.cat((c,decoder_hidden), dim=2)
    attn_h = self.attn_combine(concat_c)

    return attn_h

class End2End(nn.Module):

  def __init__(self, d_model = 147, nheads = 3, num_layers = 2):
    super(End2End, self).__init__()
    self.encoder_decoder = TransformerEncoderDecoder(d_model, nheads, num_layers)
    self.gru1 = nn.GRU(d_model, 100, batch_first=True)
    self.gru2 = nn.GRU(100, 50, batch_first=True)
    self.attention = Attention()
    self.dropout = nn.Dropout(0.4)
    self.fc = nn.Linear(50, 3)

  def forward(self, input, input_target_seq, is_train=1, pred_len=25):
    out = self.encoder_decoder(input, input_target_seq, is_train, pred_len)
    state, hidden = self.gru1(out)
    state = self.attention(hidden.permute(1,0,2), state)
    _, state = self.gru2(state)
    state = self.fc(state.squeeze(dim=0))

    return out, state

model = End2End().double().to(device)

#model = TrainModel(model, train_dataloader, valid_dataloader, 10, learning_rate=6e-4, train_force=1, c_weight=1, p_weight=0.55)

#model = TrainModel(model, train_dataloader, valid_dataloader, 20, learning_rate=1e-4, train_force=0, c_weight=1, p_weight=0.55)

model.load_state_dict(torch.load('/content/drive/My Drive/Pre-Trained Weights/IITH-END2END-P-C1P0.55.pt'))

pred, true = TestModel(model, test_dataloader, test_force=False, c_weight=1, p_weight=0.55)

from sklearn.metrics import confusion_matrix

c_m = confusion_matrix(true, pred)
print("Actual Accuracy: ", c_m.trace()/c_m.sum())

from mlxtend.plotting import plot_confusion_matrix

fig, ax = plot_confusion_matrix(conf_mat=c_m,
                                show_absolute=True,
                                show_normed=True,
                                colorbar=True)
plt.show()

import seaborn as sns

df_cm = pd.DataFrame(c_m, index = ['N','C','U'],
                  columns = ['N','C','U'])
sns.set(font_scale=3.0)
plt.figure(figsize = (6,6))
sns.heatmap(df_cm, annot=True, cbar = False, annot_kws={"size": 30}, cmap = 'Greens', linecolor='black', linewidths=0.05, fmt='.0f')

PATH = '/content/drive/My Drive/Pre-Trained Weights/IITH-END2END-N-C1P0.55.pt'
torch.save(model.state_dict(), PATH)

"""APMC Dataset"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data as utils
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch.optim as optim
from torch.autograd import Variable
from torch.nn.parameter import Parameter
import time
import torchvision.models as models

import math
from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer

device = None
if torch.cuda.is_available():
  device = torch.device('cuda')
else:
  device = torch.device('cpu')

torch.manual_seed(0)
np.random.seed(0)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

file_inputs_A = np.load('/content/drive/My Drive/Graph_Classification/APMC_features_X.npy')
file_labels_A = np.load('/content/drive/My Drive/Graph_Classification/APMC_features_y.npy')
file_inputs_A = file_inputs_A.astype('float64')
print(file_inputs_A.shape, file_labels_A.shape)

def convert_to_seqlabels(file_inputs, file_labels, seq_len = 5, pred_len = 10):
  input_sequence = []
  input_target_sequence = []
  target_sequence = []
  labels = []

  for idx, input in enumerate(file_inputs):
    input_len = input.shape[0]
    for i in range(input_len - seq_len - pred_len+1):
      input_sequence.append(input[i : i + seq_len, : ])
      input_target_sequence.append(input[i + seq_len - 1 : i + seq_len + pred_len - 1])
      target_sequence.append(input[i + seq_len : i + seq_len + pred_len])
      labels.append(file_labels[idx])

  input_sequence = np.asarray(input_sequence)
  input_target_sequence = np.asarray(input_target_sequence)
  target_sequence = np.asarray(target_sequence)
  labels = np.asarray(labels)

  return input_sequence, input_target_sequence, target_sequence, labels

def TFPrepareDataset(file_inputs_A, file_labels_A, seq_len = 15, pred_len = 25, BATCH_SIZE = 32, train_ratio = 0.7, valid_ratio = 0.1):

  input_sequence_A, input_target_sequence_A, target_sequence_A, labels_A = convert_to_seqlabels(file_inputs_A, file_labels_A, seq_len, pred_len)

  train_index_A = int(np.floor(len(input_sequence_A) * train_ratio))
  valid_index_A = int(np.floor(len(input_sequence_A) * (valid_ratio + train_ratio)))

  train_input_A, train_target_A = torch.tensor(input_sequence_A[:train_index_A]), torch.tensor(target_sequence_A[:train_index_A])
  train_input_target_A, train_labels_A = torch.tensor(input_target_sequence_A[:train_index_A]), torch.tensor(labels_A[:train_index_A])
  valid_input_A, valid_target_A = torch.tensor(input_sequence_A[train_index_A:valid_index_A]), torch.tensor(target_sequence_A[train_index_A:valid_index_A])
  valid_input_target_A, valid_labels_A = torch.tensor(input_target_sequence_A[train_index_A:valid_index_A]), torch.tensor(labels_A[train_index_A:valid_index_A])
  test_input_A, test_target_A = torch.tensor(input_sequence_A[valid_index_A:]), torch.tensor(target_sequence_A[valid_index_A:])
  test_input_target_A, test_labels_A = torch.tensor(input_target_sequence_A[valid_index_A:]), torch.tensor(labels_A[valid_index_A:])

  print("Train shapes: ", train_input_A.shape, train_input_target_A.shape, train_target_A.shape, train_labels_A.shape)
  print("Valid shapes: ", valid_input_A.shape, valid_input_target_A.shape, valid_target_A.shape, valid_labels_A.shape)
  print("Test shapes: ", test_input_A.shape, test_input_target_A.shape, test_target_A.shape, test_labels_A.shape)

  train_dataset = utils.TensorDataset(train_input_A, train_input_target_A, train_target_A, train_labels_A)
  valid_dataset = utils.TensorDataset(valid_input_A, valid_input_target_A, valid_target_A, valid_labels_A)
  test_dataset = utils.TensorDataset(test_input_A, test_input_target_A, test_target_A, test_labels_A)

  train_dataloader = utils.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last=False)
  valid_dataloader = utils.DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last=False)
  test_dataloader = utils.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last=False)

  return train_dataloader, valid_dataloader, test_dataloader

train_dataloader, valid_dataloader, test_dataloader = TFPrepareDataset(file_inputs_A, file_labels_A)

input, input_target_seq, target_seq, labels = next(iter(train_dataloader))
[batch_size, seq_len, fea_size] = input.size()
[batch_size, pred_len, fea_size] = target_seq.size()
print("Batch Size: ", batch_size)
print("Seq len: ", seq_len)
print("Prediction len: ", pred_len)
print("Input Target Seq Size: ", input_target_seq.shape)
print("Labels Size: ", labels.shape)

print(len(train_dataloader))
print(len(valid_dataloader))
print(len(test_dataloader))

def check(labels, state):
  total = 0
  cnt = 0

  for (i,j) in zip(labels, state):
    if j.argmax() == i:
      cnt+=1
    total+=1

  return cnt/total

def TrainModel(model, train_dataloader, valid_dataloader, epochs, learning_rate=1e-3, train_force=1, c_weight=0.5, p_weight=0.5):

  model = model.train()
  model = model.to(device)

  optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)
  loss_func_class = nn.CrossEntropyLoss()
  loss_func_pred = nn.MSELoss()

  curr = time.time()
  prev = time.time()

  for epoch in range(epochs):

    train_loss_c = []
    train_loss_p = []
    train_loss_t = []
    train_acc = []

    for data in train_dataloader:
      input, input_target_seq, target_seq, labels = data
      input, input_target_seq, target_seq, labels = input.to(device), input_target_seq.to(device), target_seq.to(device), labels.to(device)

      optimizer.zero_grad()
      model.zero_grad()

      if train_force == 1:
        out, state = model(input.double(), input_target_seq.double())
      else:
        out, state = model(input.double(), input_target_seq[:,0:1,:].double(), 0, pred_len)

      loss_c = loss_func_class(state, labels)
      loss_p = loss_func_pred(out, target_seq)
      total_loss = loss_c * c_weight + loss_p * p_weight

      train_loss_c.append(loss_c.data)
      train_loss_p.append(loss_p.data)
      train_loss_t.append(total_loss.data)
      train_acc.append(check(labels, state))

      total_loss.backward()
      optimizer.step()

    valid_loss_p = []
    valid_loss_c = []
    valid_loss_t = []
    valid_acc = []

    for data in valid_dataloader:
      input, input_target_seq, target_seq, labels = data
      input, input_target_seq, target_seq, labels = input.to(device), input_target_seq.to(device), target_seq.to(device), labels.to(device)

      if train_force == 1:
        out, state = model(input.double(), input_target_seq.double())
      else:
        out, state = model(input.double(), input_target_seq[:,0:1,:].double(), 0, pred_len)

      loss_c = loss_func_class(state, labels)
      loss_p = loss_func_pred(out, target_seq)

      total_loss = loss_c * c_weight + loss_p * p_weight

      valid_loss_c.append(loss_c.data)
      valid_loss_p.append(loss_p.data)
      valid_loss_t.append(total_loss.data)
      valid_acc.append(check(labels, state))

    avg_p_train = sum(train_loss_p) / len(train_loss_p)
    avg_c_train = sum(train_loss_c) / len(train_loss_c)
    avg_t_train = sum(train_loss_t) / len(train_loss_t)
    avg_acc_train = sum(train_acc) / len(train_acc)

    avg_p_valid = sum(valid_loss_p) / len(valid_loss_p)
    avg_c_valid = sum(valid_loss_c) / len(valid_loss_c)
    avg_t_valid = sum(valid_loss_t) / len(valid_loss_t)
    avg_acc_valid = sum(valid_acc) / len(valid_acc)
    curr = time.time()

    print(f"Epoch: {epoch} Time: {curr-prev :.4f}")
    print(f"Train T Loss: {avg_t_train :.4f} Train Acc: {avg_acc_train :.4f} Valid T Loss: {avg_t_valid :.4f} Valid Acc: {avg_acc_valid :.4f} ")
    print(f"Train C Loss: {avg_c_train :.4f} Train P Loss: {avg_p_train :.4f} Valid C Loss: {avg_c_valid :.4f} Valid P Loss: {avg_p_valid :.4f}")
    print("")

    prev = curr

  return model

def TestModel(model, test_dataloader, test_force = True, c_weight=0.5, p_weight=0.5):

  model = model.eval()

  loss_func_class = nn.CrossEntropyLoss()
  loss_func_pred = nn.MSELoss()

  test_loss_c = []
  test_loss_p = []
  test_loss_t = []
  test_acc = []
  pred = []
  true = []

  for data in test_dataloader:
    input, input_target_seq, target_seq, labels = data
    input, input_target_seq, target_seq, labels = input.to(device), input_target_seq.to(device), target_seq.to(device), labels.to(device)

    if test_force == True:
      out, state = model(input.double(), input_target_seq.double())
    else:
      out, state = model(input.double(), input_target_seq[:,0:1,:].double(), 0, pred_len)

    loss_p = loss_func_pred(out, target_seq)
    loss_c = loss_func_class(state, labels)

    total_loss = loss_p * p_weight + loss_c * c_weight

    test_loss_c.append(loss_c.data)
    test_loss_p.append(loss_p.data)
    test_loss_t.append(total_loss.data)
    test_acc.append(check(labels, state))

    for x in state:
      pred.append(x.argmax().cpu().data.numpy())
    for x in labels:
      true.append(x.cpu().data.numpy())

  avg_p = sum(test_loss_p) / len(test_loss_p)
  avg_c = sum(test_loss_c) / len(test_loss_c)
  avg_t = sum(test_loss_t) / len(test_loss_t)
  avg_acc = sum(test_acc) / len(test_acc)

  print(f"P Loss: {avg_p :.4f} C Loss: {avg_c :.4f} T Loss: {avg_t :.4f} Acc: {avg_acc :.4f}")
  return pred, true

class PositionalEncoding(nn.Module):

    def __init__(self, d_model, dropout=0.1, max_len=5000):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(p=dropout)

        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)[:,:-1]
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)

    def forward(self, x):
        x = x + self.pe[:x.size(0), :]
        return self.dropout(x)

class TransformerEncoderDecoder(nn.Module):

  def __init__(self, d_model = 147, nheads = 3, num_layers = 2):

    super(TransformerEncoderDecoder, self).__init__()
    encoder_layer = nn.TransformerEncoderLayer(d_model, nheads)
    self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)
    self.postional_encode = PositionalEncoding(d_model)
    decoder_layer = nn.TransformerDecoderLayer(d_model, nheads)
    self.decoder = nn.TransformerDecoder(decoder_layer, num_layers)
    self.encoder_mask = None
    self.decoder_mask = None
    self.d_model = d_model

  def generate_mask(self, src_len):
    mask = (torch.triu(torch.ones(src_len,src_len)) == 1).transpose(0,1)
    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))

    return mask

  def forward(self, input, target, is_train = 1, pred_length = 2):

    input = input.permute(1, 0, 2)
    target = target.permute(1, 0, 2)

    if self.encoder_mask is None or self.encoder_mask.size(0) != len(input):
      mask = self.generate_mask(len(input)).to(device)
      self.encoder_mask = mask

    if self.decoder_mask is None or self.decoder_mask.size(0) != len(target):
      mask = self.generate_mask(len(target)).to(device)
      self.decoder_mask = mask

    src = self.postional_encode(input)
    encoder_out = self.encoder(src, self.encoder_mask)

    if is_train == 1:
      decoder_out = self.decoder(target, encoder_out, self.decoder_mask)
      return decoder_out.permute(1,0,2)

    else:
      outputs = None
      for i in range(pred_length):
        decoder_out = self.decoder(target, encoder_out, self.decoder_mask)
        if outputs is None:
            outputs = decoder_out
        else:
            outputs = torch.cat((outputs, decoder_out), 0)
        target = decoder_out
      return outputs.permute(1,0,2)

class Attention(nn.Module):
  def __init__(self, hidden_size=100):
    super(Attention, self).__init__()
    self.attn_combine = nn.Linear(hidden_size+hidden_size, hidden_size)

  def forward(self, decoder_hidden, encoder_out):
    attn_weights = F.softmax(torch.bmm(decoder_hidden, encoder_out.permute(0,2,1)), dim=2)
    c = torch.bmm(attn_weights, encoder_out)
    concat_c = torch.cat((c,decoder_hidden), dim=2)
    attn_h = self.attn_combine(concat_c)

    return attn_h

class End2End(nn.Module):

  def __init__(self, d_model = 147, nheads = 3, num_layers = 2):
    super(End2End, self).__init__()
    self.encoder_decoder = TransformerEncoderDecoder(d_model, nheads, num_layers)
    self.gru1 = nn.GRU(d_model, 100, batch_first=True)
    self.gru2 = nn.GRU(100, 50, batch_first=True)
    self.attention = Attention()
    self.dropout = nn.Dropout(0.4)
    self.fc = nn.Linear(50, 3)

  def forward(self, input, input_target_seq, is_train=1, pred_len=25):
    out = self.encoder_decoder(input, input_target_seq, is_train, pred_len)
    state, hidden = self.gru1(out)
    state = self.attention(hidden.permute(1,0,2), state)
    _, state = self.gru2(state)
    state = self.fc(state.squeeze(dim=0))

    return out, state

model = End2End().double().to(device)

#model = TrainModel(model, train_dataloader, valid_dataloader, 10, learning_rate=6e-4, train_force=1, c_weight=1, p_weight=0.55)

#model = TrainModel(model, train_dataloader, valid_dataloader, 20, learning_rate=1e-4, train_force=0, c_weight=1, p_weight=0.55)

model.load_state_dict(torch.load('/content/drive/My Drive/Pre-Trained Weights/IITH-END2END-APMC-C1P0.55.pt'))

pred, true = TestModel(model, test_dataloader, test_force=False, c_weight=1, p_weight=0.55)

from sklearn.metrics import confusion_matrix

c_m = confusion_matrix(true, pred)
print("Actual Accuracy: ", c_m.trace()/c_m.sum())

from mlxtend.plotting import plot_confusion_matrix

fig, ax = plot_confusion_matrix(conf_mat=c_m,
                                show_absolute=True,
                                show_normed=True,
                                colorbar=True)
plt.show()

import seaborn as sns

df_cm = pd.DataFrame(c_m, index = ['N','C','U'],
                  columns = ['N','C','U'])
sns.set(font_scale=3.0)
plt.figure(figsize = (6,6))
sns.heatmap(df_cm, annot=True, cbar = False, annot_kws={"size": 30}, cmap = 'Greens', linecolor='black', linewidths=0.05, fmt='.0f')

PATH = '/content/drive/My Drive/Pre-Trained Weights/IITH-END2END-APMC-C1P0.55.pt'
torch.save(model.state_dict(), PATH)

