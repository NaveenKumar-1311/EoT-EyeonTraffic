# -*- coding: utf-8 -*-
"""Predic_seq_to_dynamic_lengths.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10JaDic6oBfml2k20Cz4EP65r_cL0gFN3

**Sequence prediction using ConvLSTM**

Importing different libraries
"""

import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data as utils
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch.optim as optim
from torch.autograd import Variable
from torch.nn.parameter import Parameter

"""Selecting the device to work with"""

device = None
if torch.cuda.is_available():
  device = torch.device('cuda')
else:
  device = torch.device('cpu')

"""Loading the dataset"""

file_inputs = np.load('/content/drive/My Drive/Graph_Classification/Paldi_features_X.npy')
file_labels = np.load('/content/drive/My Drive/Graph_Classification/Paldi_labels_y.npy')

print(file_inputs.shape)
print(file_labels.shape)

"""Defining the dataset preperation function. Here we create the sequence inputs and target and load then as a torch dataloader"""

def PrepareDataset(file_inputs, seq_len = 20, pred_len = 1, BATCH_SIZE = 32, train_ratio = 0.8):

  input_sequence = []
  target_sequence = []
  for input in file_inputs:
    input_len = input.shape[0]
    for i in range(input_len - seq_len - pred_len):
      input_sequence.append(input[i:i+seq_len, : ])
      target_sequence.append(input[i+seq_len:i+seq_len+pred_len])
  input_sequence = np.asarray(input_sequence)
  target_sequence = np.asarray(target_sequence)
  print("Input Sequence Shape: ", input_sequence.shape)
  print("Target Sequence Shape: ", target_sequence.shape)

  train_index = int(np.floor(len(input_sequence) * train_ratio))

  train_input, train_target = torch.tensor(input_sequence[:train_index]), torch.tensor(target_sequence[:train_index])
  test_input, test_target = torch.tensor(input_sequence[train_index:]), torch.tensor(target_sequence[train_index:])

  train_dataset = utils.TensorDataset(train_input, train_target)
  test_dataset = utils.TensorDataset(test_input, test_target)

  train_dataloader = utils.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, drop_last = True)
  test_dataloader = utils.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = True, drop_last= True)

  return train_dataloader, test_dataloader

"""Using the previously defined dataset preperation function and obtaining train and test dataloaders"""

train_dataloader, test_dataloader = PrepareDataset(file_inputs)

input, labels = next(iter(train_dataloader))
[batch_size, seq_len, fea_size] = input.size()
[batch_size, pred_len, fea_size] = labels.size()
print("Batch Size: ", batch_size)
print("Seq len: ", seq_len)
print("Prediction len: ", pred_len)

"""Here we define our train function. We have used RMSprop optimizer and MSE as our loss function (since the data we are working is kind of a time series data). We train our model for assigned number of epochs. In each epoch we train out model on train data and test on the validation data."""

def Train(model, train_dataloader, test_dataloader, epochs = 10, learning_rate = 1e-3):

  model = model.to(device)
  optimizer = optim.RMSprop(model.parameters(), learning_rate)
  loss_func = nn.MSELoss()

  cur_time = time.time()
  pre_time = time.time()

  for epoch in range(epochs):
    train_loss = []
    test_loss = []
    for data in train_dataloader:
      input, labels = data
      input, labels = input.to(device), labels.to(device)

      optimizer.zero_grad()
      model.zero_grad()

      out = model(input.double())
      loss_train = loss_func(out, labels)
      train_loss.append(loss_train.data)

      loss_train.backward()
      optimizer.step()

    for data in test_dataloader:
      val_input, val_labels = data
      val_input, val_labels = val_input.to(device), val_labels.to(device)

      val_out = model(val_input.double())
      val_loss = loss_func(out, val_labels)
      test_loss.append(val_loss.data)


    avg_train_loss = sum(train_loss) / len(train_loss)
    avg_valid_loss = sum(test_loss) / len(test_loss)
    cur_time = time.time()

    print(f'Epochs: {epoch}  Train Loss: {avg_train_loss}  Test Loss: {avg_valid_loss} Time: {cur_time - pre_time}')
    pre_time = cur_time
  return model

"""Here we define our ConvLSTM model. We process each sequence of input one by one first passing it through a Conv1D layer and the concatenating with previous hidden state and then passing to the LSTM cell"""

class ConvLSTM(nn.Module):
    def __init__(self, input_size, cell_size, hidden_size, pred_length):
        """
        cell_size is the size of cell_state.
        hidden_size is the size of hidden_state, or say the output_state of each step
        """
        super(ConvLSTM, self).__init__()

        self.cell_size = cell_size
        self.hidden_size = hidden_size
        self.pred_length = pred_length
        self.fl = nn.Linear(input_size + hidden_size, hidden_size)
        self.il = nn.Linear(input_size + hidden_size, hidden_size)
        self.ol = nn.Linear(input_size + hidden_size, hidden_size)
        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)

        self.conv = nn.Conv1d(1, hidden_size, hidden_size)

    def step(self, input, Hidden_State, Cell_State):

        conv = self.conv(input)
        conv = torch.squeeze(conv)

        combined = torch.cat((conv, Hidden_State), 1)

        f = torch.sigmoid(self.fl(combined))
        i = torch.sigmoid(self.il(combined))
        o = torch.sigmoid(self.ol(combined))
        C = torch.tanh(self.Cl(combined))
        Cell_State = f * Cell_State + i * C
        Hidden_State = o * torch.tanh(Cell_State)

        return Hidden_State, Cell_State

    def forward(self, inputs):

        batch_size = inputs.size(0)
        time_step = inputs.size(1)
        Hidden_State, Cell_State = self.initHidden(batch_size)
        outputs = None

        for i in range(time_step + self.pred_length - 1):
            if i < time_step:
              Hidden_State, Cell_State = self.step(inputs[:,i:i+1,:], Hidden_State, Cell_State)
            else:
              Hidden_State, Cell_State = self.step(Hidden_State.unsqueeze(1), Hidden_State, Cell_State)
            if outputs is None:
                outputs = Hidden_State.unsqueeze(1)
            else:
                outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)

        outputs = outputs[ : , -self.pred_length : , : ]
        return outputs

    def initHidden(self, batch_size):
        use_gpu = torch.cuda.is_available()
        if use_gpu:
            Hidden_State = torch.zeros(batch_size, self.hidden_size, dtype = torch.float64).cuda()
            Cell_State = torch.zeros(batch_size, self.hidden_size, dtype = torch.float64).cuda()
            return Hidden_State, Cell_State
        else:
            Hidden_State = torch.zeros(batch_size, self.hidden_size)
            Cell_State = torch.zeros(batch_size, self.hidden_size)
            return Hidden_State, Cell_State

model = ConvLSTM(fea_size, fea_size, fea_size, pred_len).double().to(device)

net = Train(model, train_dataloader, test_dataloader, epochs = 30, learning_rate = 1e-4)

"""**Sequence prediction using Transformers**

Importing different libraries
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data as utils
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch.optim as optim
from torch.autograd import Variable
from torch.nn.parameter import Parameter
import time

import math
from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer

"""Selecting the device to work with"""

device = None
if torch.cuda.is_available():
  device = torch.device('cuda')
else:
  device = torch.device('cpu')

"""Loading the data"""

file_inputs = np.load('/content/drive/My Drive/Graph_Classification/Paldi_features_X.npy')
file_labels = np.load('/content/drive/My Drive/Graph_Classification/Paldi_labels_y.npy')

print(file_inputs.shape)
print(file_labels.shape)

"""Defining the dataset preperation function. Here we create the sequence inputs and target and load then as a torch dataloader"""

def TFPrepareDataset(file_inputs, seq_len = 20, pred_len = 10, BATCH_SIZE = 32, train_ratio = 0.8):

  input_sequence = []
  input_target_sequence = []
  target_sequence = []
  for input in file_inputs:
    input_len = input.shape[0]
    for i in range(input_len - seq_len - pred_len):
      input_sequence.append(input[i : i + seq_len, : ])
      input_target_sequence.append(input[i + seq_len - 1 : i + seq_len + pred_len - 1])
      target_sequence.append(input[i + seq_len : i + seq_len + pred_len])
  input_sequence = np.asarray(input_sequence)
  input_target_sequence = np.asarray(input_target_sequence)
  target_sequence = np.asarray(target_sequence)
  print("Input Sequence Shape: ", input_sequence.shape)
  print("Input Target Sequence Shape: ", input_target_sequence.shape)
  print("Target Sequence Shape: ", target_sequence.shape)

  train_index = int(np.floor(len(input_sequence) * train_ratio))

  train_input, train_target = torch.tensor(input_sequence[:train_index]), torch.tensor(target_sequence[:train_index])
  train_input_target = torch.tensor(input_target_sequence[:train_index])
  test_input, test_target = torch.tensor(input_sequence[train_index:]), torch.tensor(target_sequence[train_index:])
  test_input_target = torch.tensor(input_target_sequence[train_index:])

  train_dataset = utils.TensorDataset(train_input, train_input_target, train_target)
  test_dataset = utils.TensorDataset(test_input, test_input_target, test_target)

  train_dataloader = utils.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, drop_last = True)
  test_dataloader = utils.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = True, drop_last= True)

  return train_dataloader, test_dataloader

"""Using the previously defined dataset preperation function and obtaining train and test dataloaders"""

train_dataloader, test_dataloader = TFPrepareDataset(file_inputs)

input, input_labels, labels = next(iter(train_dataloader))
[batch_size, seq_len, fea_size] = input.size()
[batch_size, pred_len, fea_size] = labels.size()
print("Batch Size: ", batch_size)
print("Seq len: ", seq_len)
print("Prediction len: ", pred_len)
print("Input Target Seq Size: ", input_labels.shape)

"""Here we define our train function. We have used RMSprop optimizer and MSE as our loss function (since the data we are working is kind of a time series data). We train our model for assigned number of epochs. In each epoch we train out model on train data and test on the validation data. The function also takes an argument valid_force which when set to true applies teacher forcing during validation and when set to false doesn't apply teacher forcing during validation"""

def TFTrain(model, train_dataloader, test_dataloader, epochs = 10, learning_rate = 1e-4, valid_force = True):

  model = model.to(device)
  optimizer = optim.RMSprop(model.parameters(), learning_rate)
  loss_func = nn.MSELoss()

  curr = time.time()
  prev = time.time()

  for epoch in range(epochs):
    train_loss = []
    test_loss = []
    for data in train_dataloader:
      input, input_labels, labels = data
      input, input_labels, labels = input.to(device), input_labels.to(device), labels.to(device)

      optimizer.zero_grad()
      model.zero_grad()

      out = model(input.double(), input_labels.double())
      loss_train = loss_func(out, labels)
      train_loss.append(loss_train.data)

      loss_train.backward()
      optimizer.step()

    for data in test_dataloader:
      val_input, val_input_labels, val_labels = data
      val_input, val_input_labels, val_labels = val_input.to(device), val_input_labels.to(device), val_labels.to(device)

      if valid_force == True:
        val_out = model(val_input.double(), val_input_labels)
      else:
        val_out = model(val_input.double(), val_input_labels[:,0:1,:].double(), 0, pred_len)
      val_loss = loss_func(val_out, val_labels)
      test_loss.append(val_loss.data)


    avg_train_loss = sum(train_loss) / len(train_loss)
    avg_valid_loss = sum(test_loss) / len(test_loss)
    curr = time.time()

    print(f'Epochs: {epoch}  Train Loss: {avg_train_loss}  Test Loss: {avg_valid_loss} Time: {curr-prev}')
    prev = curr
  return model

class EncoderGRU(nn.Module):
    def __init__(self, hidden_size=147):
        super(EncoderGRU, self).__init__()
        self.hidden_size = hidden_size
        self.gru1 = nn.LSTM(hidden_size, 100, batch_first = True)
        self.gru2 = nn.LSTM(100, hidden_size, batch_first = True)

    def forward(self, inputs):
        inputs, (hidden, cell) = self.gru1(inputs)
        outputs, (Hidden_State, cell) = self.gru2(inputs)
        return outputs, Hidden_State, cell

class DecoderGRU(nn.Module):
    def __init__(self, hidden_size=147, pred_len=10):
        super(DecoderGRU, self).__init__()
        self.hidden_size = hidden_size
        self.gru = nn.LSTM(hidden_size, hidden_size, batch_first=True)
        self.pred_len = pred_len

    def forward(self, input, hidden, cell):
        output, (hidden, _) = self.gru(input, (hidden, cell))
        return output[:,-self.pred_len:,:]

class Seq2Seq(nn.Module):

  def __init__(self, hidden_size=147, pred_len = 10):
    super(Seq2Seq,self).__init__()
    self.encoder = EncoderGRU(hidden_size)
    self.decoder = DecoderGRU(hidden_size, pred_len)

  def forward(self, encoder_input, decoder_input, is_train = 1, pred_len=10):
    outputs, hidden, cell = self.encoder(encoder_input)
    final_out = self.decoder(decoder_input, hidden, cell)

    return final_out

net = Seq2Seq(fea_size).double().to(device)

X = torch.randn((32,20,147)).to(device)
y = torch.randn((32,10,147)).to(device)

final_out = net(X.double(),y.double())
final_out.shape

net = TFTrain(net, train_dataloader, test_dataloader, learning_rate = 1e-3, epochs = 50)

net = TFTrain(net, train_dataloader, test_dataloader, learning_rate = 1e-2, epochs = 50)

"""Since, we are using transformer model we need to first positionally encoder the input vectors."""

class PositionalEncoding(nn.Module):

    def __init__(self, d_model, dropout=0.1, max_len=5000):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(p=dropout)

        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)[:,:-1]
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)

    def forward(self, x):
        x = x + self.pe[:x.size(0), :]
        return self.dropout(x)

"""Here we have defined our transformer model. We use the default transformers provided by Pytorch. We have also defined mask variables which stop our encoder and decoder layers from cheating on the input data"""

class TransformerEncoderDecoder(nn.Module):

  def __init__(self, d_model = 147, nheads = 3, num_layers = 2):

    super(TransformerEncoderDecoder, self).__init__()
    encoder_layer = nn.TransformerEncoderLayer(d_model, nheads)
    self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)
    self.postional_encode = PositionalEncoding(d_model)
    decoder_layer = nn.TransformerDecoderLayer(d_model, nheads)
    self.decoder = nn.TransformerDecoder(decoder_layer, num_layers)
    self.encoder_mask = None
    self.decoder_mask = None
    self.d_model = d_model

  def generate_mask(self, src_len):
    mask = (torch.triu(torch.ones(src_len,src_len)) == 1).transpose(0,1)
    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))

    return mask

  def forward(self, input, target, is_train = 1, pred_length = 2):

    input = input.permute(1, 0, 2)
    target = target.permute(1, 0, 2)

    if self.encoder_mask is None or self.encoder_mask.size(0) != len(input):
      mask = self.generate_mask(len(input)).to(device)
      self.encoder_mask = mask

    if self.decoder_mask is None or self.decoder_mask.size(0) != len(target):
      mask = self.generate_mask(len(target)).to(device)
      self.decoder_mask = mask

    src = self.postional_encode(input)
    encoder_out = self.encoder(src, self.encoder_mask)

    if is_train == 1:
      decoder_out = self.decoder(target, encoder_out, self.decoder_mask)
      return decoder_out.permute(1,0,2)

    else:
      outputs = None
      for i in range(pred_length):
        decoder_out = self.decoder(target, encoder_out, self.decoder_mask)
        if outputs is None:
            outputs = decoder_out
        else:
            outputs = torch.cat((outputs, decoder_out), 0)
        target = decoder_out
      return outputs.permute(1,0,2)

trans_net = TransformerEncoderDecoder().double().to(device)

"""We train our model by enabling teacher forceing for validation dataset by setting valid_force == True (default value)."""

trans_net = TFTrain(trans_net, train_dataloader, test_dataloader, learning_rate = 1e-3, epochs = 50)

trans_net = TFTrain(trans_net, train_dataloader, test_dataloader, learning_rate = 1e-4, epochs = 50)

"""We train our model by disabling teacher forceing for validation dataset by setting valid_force == False."""

trans_net = TFTrain(trans_net, train_dataloader, test_dataloader, epochs = 10, valid_force = False)

"""Saving Model weights"""

torch.save(trans_net.state_dict(),'/content/drive/My Drive/Pre-Trained Weights/model.pt')

"""Loading the model weights"""

PATH = '/content/drive/My Drive/Pre-Trained Weights/IITH-transformer_generation-005.pt'
trans_net.load_state_dict(torch.load(PATH))
trans_net.eval()

"""**Sequence Predictor and Classifier**"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data as utils
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch.optim as optim
from torch.autograd import Variable
from torch.nn.parameter import Parameter
import time
import torchvision.models as models

import math
from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer

device = None
if torch.cuda.is_available():
  device = torch.device('cuda')
else:
  device = torch.device('cpu')

file_inputs = np.load('/content/drive/My Drive/Graph_Classification/Paldi_features_X.npy')
file_labels = np.load('/content/drive/My Drive/Graph_Classification/Paldi_labels_y.npy')

print(file_inputs.shape)
print(file_labels.shape)

def TFPrepareDataset(file_inputs, file_labels, seq_len = 20, pred_len = 10, BATCH_SIZE = 32, train_ratio = 0.8):

  input_sequence = []
  input_target_sequence = []
  target_sequence = []
  labels = []
  for idx, input in enumerate(file_inputs):
    input_len = input.shape[0]
    for i in range(input_len - seq_len - pred_len):
      input_sequence.append(input[i : i + seq_len, : ])
      input_target_sequence.append(input[i + seq_len - 1 : i + seq_len + pred_len - 1])
      target_sequence.append(input[i + seq_len : i + seq_len + pred_len])
      labels.append(file_labels[idx])

  input_sequence = np.asarray(input_sequence)
  input_target_sequence = np.asarray(input_target_sequence)
  target_sequence = np.asarray(target_sequence)
  labels = np.asarray(labels)

  print("Input Sequence Shape: ", input_sequence.shape)
  print("Input Target Sequence Shape: ", input_target_sequence.shape)
  print("Target Sequence Shape: ", target_sequence.shape)
  print("labels Shape: ", labels.shape)

  train_index = int(np.floor(len(input_sequence) * train_ratio))

  train_input, train_target = torch.tensor(input_sequence[:train_index]), torch.tensor(target_sequence[:train_index])
  train_input_target = torch.tensor(input_target_sequence[:train_index])
  train_labels = torch.tensor(labels[:train_index])

  test_input, test_target = torch.tensor(input_sequence[train_index:]), torch.tensor(target_sequence[train_index:])
  test_input_target = torch.tensor(input_target_sequence[train_index:])
  test_labels = torch.tensor(labels[train_index:])

  train_dataset = utils.TensorDataset(train_input, train_input_target, train_target, train_labels)
  test_dataset = utils.TensorDataset(test_input, test_input_target, test_target, test_labels)

  train_dataloader = utils.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, drop_last = True)
  test_dataloader = utils.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = True, drop_last= True)

  return train_dataloader, test_dataloader

train_dataloader, test_dataloader = TFPrepareDataset(file_inputs, file_labels)

input, input_target_seq, target_seq, labels = next(iter(train_dataloader))
[batch_size, seq_len, fea_size] = input.size()
[batch_size, pred_len, fea_size] = target_seq.size()
print("Batch Size: ", batch_size)
print("Seq len: ", seq_len)
print("Prediction len: ", pred_len)
print("Input Target Seq Size: ", input_target_seq.shape)
print("Labels Size: ", labels.shape)

print(len(train_dataloader))
print(len(test_dataloader))

class PositionalEncoding(nn.Module):

    def __init__(self, d_model, dropout=0.1, max_len=5000):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(p=dropout)

        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)[:,:-1]
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)

    def forward(self, x):
        x = x + self.pe[:x.size(0), :]
        return self.dropout(x)

class TransformerEncoderDecoder(nn.Module):

  def __init__(self, d_model = 147, nheads = 3, num_layers = 2):

    super(TransformerEncoderDecoder, self).__init__()
    encoder_layer = nn.TransformerEncoderLayer(d_model, nheads)
    self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)
    self.postional_encode = PositionalEncoding(d_model)
    decoder_layer = nn.TransformerDecoderLayer(d_model, nheads)
    self.decoder = nn.TransformerDecoder(decoder_layer, num_layers)
    self.encoder_mask = None
    self.decoder_mask = None
    self.d_model = d_model

  def generate_mask(self, src_len):
    mask = (torch.triu(torch.ones(src_len,src_len)) == 1).transpose(0,1)
    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))

    return mask

  def forward(self, input, target, is_train = 1, pred_length = 2):

    input = input.permute(1, 0, 2)
    target = target.permute(1, 0, 2)

    if self.encoder_mask is None or self.encoder_mask.size(0) != len(input):
      mask = self.generate_mask(len(input)).to(device)
      self.encoder_mask = mask

    if self.decoder_mask is None or self.decoder_mask.size(0) != len(target):
      mask = self.generate_mask(len(target)).to(device)
      self.decoder_mask = mask

    src = self.postional_encode(input)
    encoder_out = self.encoder(src, self.encoder_mask)

    if is_train == 1:
      decoder_out = self.decoder(target, encoder_out, self.decoder_mask)
      return decoder_out.permute(1,0,2)

    else:
      outputs = None
      for i in range(pred_length):
        decoder_out = self.decoder(target, encoder_out, self.decoder_mask)
        if outputs is None:
            outputs = decoder_out
        else:
            outputs = torch.cat((outputs, decoder_out), 0)
        target = decoder_out
      return outputs.permute(1,0,2)

trans_net = TransformerEncoderDecoder().double().to(device)

PATH = '/content/drive/My Drive/Pre-Trained Weights/IITH-transformer_generation-005.pt'
trans_net.load_state_dict(torch.load(PATH))
trans_net.eval()

def final_outputs(model, train_dataloader, test_dataloader, valid_force = True):

  final_outs = []
  final_labels = []

  model.eval()

  for idx, data in enumerate(train_dataloader):

    input, input_target_seq, target_seq, labels = data
    input, input_target_seq = input.to(device), input_target_seq.to(device)

    out1 = model(input.double(), input_target_seq.double())
    out = out1.to(torch.device('cpu')).clone().detach()

    final_outs.append(out)
    final_labels.append(labels)

  for idx, data in enumerate(test_dataloader):

    input, input_target_seq, target_seq, labels = data
    input, input_target_seq = input.to(device), input_target_seq.to(device)

    out1 = model(input.double(), input_target_seq.double())
    out = out1.to(torch.device('cpu')).clone().detach()

    final_outs.append(out)
    final_labels.append(labels)

  return final_outs, final_labels

final_outs, final_labels = final_outputs(trans_net, train_dataloader, test_dataloader)

print(len(final_outs), len(final_labels))

train_index = 250
train_outs, train_labels = final_outs[ :train_index], final_labels[ :train_index]
test_outs, test_labels = final_outs[train_index: ], final_labels[train_index: ]

def check(outputs, labels):
  total = 0
  correct = 0
  for i,j in zip(outputs, labels):
    if i.argmax() == j:
      correct += 1
    total += 1
  return correct/total

def FinalTrain(model, train_outs, train_labels, test_outs, test_labels, lr = 1e-4, epochs = 20):


  optimizer = optim.Adam(model.parameters(), lr = lr)
  loss_func = nn.CrossEntropyLoss()

  cur_time = time.time()
  pre_time = time.time()

  for epoch in range(epochs):

    train_loss = []
    train_acc = []
    test_loss = []
    test_acc = []

    for (input, labels) in zip(train_outs, train_labels):

      input, labels = input.to(device), labels.to(device)

      optimizer.zero_grad()
      model.zero_grad()

      out = model(input.double())
      loss = loss_func(out, labels)

      train_loss.append(loss.data)
      train_acc.append(check(out,labels))

      loss.backward()
      optimizer.step()

    for (input, labels) in zip(test_outs, test_labels):

      input, labels = input.to(device), labels.to(device)

      out = model(input.double())
      loss = loss_func(out, labels)

      test_loss.append(loss.data)
      test_acc.append(check(out, labels))

    cur_time = time.time()
    avg_train_loss = sum(train_loss) / len(train_loss)
    avg_train_acc = sum(train_acc) / len(train_acc)
    avg_test_loss = sum(test_loss) / len(test_loss)
    avg_test_acc = sum(test_acc) / len(test_acc)

    print(f'Epochs: {epoch} Train Loss: {avg_train_loss} Train Acc: {avg_train_acc} Test Loss: {avg_test_loss} Test Acc: {avg_test_acc} Time: {cur_time - pre_time}')
    pre_time = cur_time

  return model

class PositionalEncoding(nn.Module):

    def __init__(self, d_model, dropout=0.1, max_len=50):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(p=dropout)

        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)[:,:-1]
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)

    def forward(self, x):
        x = x + self.pe[:x.size(0), :]
        return self.dropout(x)

class TransformerClassifier(nn.Module):

  def __init__(self, nclasses = 3, ndim = 147, nheads = 7, nhid = 512, nlayers = 3, dropout = 0.4):

    super(TransformerClassifier, self).__init__()
    encoder_layer = TransformerEncoderLayer(ndim, nheads, nhid)
    self.encoder = TransformerEncoder(encoder_layer, nlayers)
    self.positional = PositionalEncoding(ndim)
    self.src_mask = None
    self.ndim = ndim
    self.fc = nn.Linear(ndim, nclasses)

  def _generate_src_mask(self, sz):

    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1).to(device)
    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))
    return mask

  def reduced_sum(self,out):

    size = out.shape
    final_out = torch.zeros(size[0],size[2]).to(device)
    for i in range(size[0]):
      final_out[i,0] = torch.sum(out[i,:,0])
      final_out[i,1] = torch.sum(out[i,:,1])
      final_out[i,2] = torch.sum(out[i,:,2])
    return final_out/size[1]


  def forward(self, input):

    input = input.permute(1,0,2)
    if self.src_mask is None or self.src_mask.size(0) != len(input):
      mask = self._generate_src_mask(len(input))
      self.src_mask = mask

    positonal = self.positional(input)
    out = self.encoder(positonal, self.src_mask)
    out = (out + input)
    out = out.permute(1,0,2)
    out = self.fc(out)
    out = F.softmax(self.reduced_sum(out),dim = 1)
    return out

model = TransformerClassifier().double().to(device)
PATH = '/content/drive/My Drive/Pre-Trained Weights/IITH-transformer_classifier-90%.pt'
model.load_state_dict(torch.load(PATH))

model = FinalTrain(model, train_outs, train_labels, test_outs, test_labels,lr = 1e-4, epochs = 20)

model = FinalTrain(model, train_outs, train_labels, test_outs, test_labels,lr = 1e-4, epochs = 50)

model = FinalTrain(model, train_outs, train_labels, test_outs, test_labels,lr = 1e-4, epochs = 100)

torch.save(model.state_dict(),'/content/drive/My Drive/Pre-Trained Weights/IITH_Final_65.pt')

"""Classifier"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torchvision.models as models
import torch.nn.functional as F
import torch.utils.data as utils
import time

device = None
if torch.cuda.is_available():
  device = torch.device('cuda')
else:
  device = torch.device('cpu')

file_inputs = np.load('/content/drive/My Drive/Graph_Classification/Paldi_features_X.npy')
file_labels = np.load('/content/drive/My Drive/Graph_Classification/Paldi_labels_y.npy')

def plotshow(img, cmap = None):
  plt.imshow(img, cmap = cmap)
  plt.show()

plotshow(file_inputs[0])
print(file_labels[0])
plotshow(file_inputs[1])
print(file_labels[1])
plotshow(file_inputs[2])
print(file_labels[2])

print(file_inputs.shape)
print(file_labels.shape)

def PrepareData(inputs, labels, train_proportion = 0.8, valid_proportion = 0.1, batch_size = 20):
  sample_size = len(inputs)
  train_length = int(train_proportion*sample_size)
  valid_length = int((train_proportion + valid_proportion)*sample_size)

  print(train_length)
  print(valid_length)

  train_input, train_label = inputs[:train_length], labels[:train_length]
  valid_input, valid_label = inputs[train_length:valid_length], labels[train_length:valid_length]
  test_input, test_label = inputs[valid_length:], labels[valid_length:]

  train_input, train_label = torch.tensor(train_input), torch.tensor(train_label)
  valid_input, valid_label = torch.tensor(valid_input), torch.tensor(valid_label)
  test_input, test_label = torch.tensor(test_input), torch.tensor(test_label)

  train_dataset = utils.TensorDataset(train_input, train_label)
  valid_dataset = utils.TensorDataset(valid_input, valid_label)
  test_dataset = utils.TensorDataset(test_input, test_label)

  train_dataloader = utils.DataLoader(train_dataset,batch_size = batch_size, shuffle = True, drop_last = True)
  valid_dataloader = utils.DataLoader(valid_dataset,batch_size = batch_size, shuffle = True, drop_last = True)
  test_dataloader = utils.DataLoader(test_dataset, batch_size = batch_size, shuffle = True, drop_last = True)

  return train_dataloader, valid_dataloader, test_dataloader

train_dataloader, valid_dataloader, test_dataloader = PrepareData(file_inputs, file_labels)

input, label = next(iter(train_dataloader))
[batch_size, height, width] = input.size()
print(batch_size)
print(height)
print(width)
print(label.shape)
print(input.dtype)

def check(outputs, labels):
  total = 0
  correct = 0
  for i,j in zip(outputs, labels):
    if i.argmax() == j:
      correct += 1
    total += 1
  return correct/total

def TrainModel( model, train_dataloader, valid_dataloader, learning_rate = 1e-4, num_epochs = 300):

  input, label = next(iter(train_dataloader))
  [batch_size, height, width] = input.size()

  #device = torch.device('cpu')
  model.to(device)

  loss = torch.nn.CrossEntropyLoss()

  learning_rate = learning_rate
  optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)

  use_gpu = torch.cuda.is_available()

  cur_time = time.time()
  pre_time = time.time()

  for epoch in range(num_epochs):

    trained_number = 0

    valid_dataloader_iter = iter(valid_dataloader)

    losses_epochs_train = []
    losses_epochs_valid = []
    accuracy_train = []
    accuracy_valid = []

    for data in train_dataloader:
      inputs, labels = data

      if input.shape[0] != batch_size:
        continue

      inputs, labels = inputs.to(device), labels.to(device)

      model.zero_grad()

      outputs = model(inputs.double())

      loss_train = loss(outputs, labels)
      losses_epochs_train.append(loss_train.data)
      accuracy_train.append(check(outputs, labels))

      optimizer.zero_grad()
      loss_train.backward()
      optimizer.step()

      try:
        inputs_val, labels_val = next(valid_dataloader_iter)
      except StopIteration:
        valid_dataloader_iter = iter(valid_dataloader)
        inputs_val, labels_val = next(valid_dataloader_iter)

      inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)

      outputs_val = model(inputs_val.double())
      loss_valid = loss(outputs_val, labels_val)
      losses_epochs_valid.append(loss_valid.data)
      accuracy_valid.append(check(outputs_val, labels_val))

      trained_number += 1

    avg_losses_epochs_train = sum(losses_epochs_train) / float(len(losses_epochs_train))
    avg_losses_epochs_valid = sum(losses_epochs_valid) / float(len(losses_epochs_valid))
    avg_acc_train = sum(accuracy_train) / float(len(accuracy_train))
    avg_acc_valid = sum(accuracy_valid) / float(len(accuracy_valid))

    cur_time = time.time()
    print(f'Epochs: {epoch}, train_loss: {avg_losses_epochs_train}, train_acc: {avg_acc_train}, valid_loss: {avg_losses_epochs_valid}, valid acc: {avg_acc_valid}, time: {cur_time - pre_time}')
    pre_time = cur_time

  return model

def TestModel(model, test_dataloader):

  test_acc = []
  test_loss = []
  loss_func = torch.nn.CrossEntropyLoss()
  pred = []
  true = []

  model.eval()

  for input, labels in test_dataloader:

    input, labels = input.to(device), labels.to(device)

    out = model(input.double())

    loss = loss_func(out, labels)
    test_loss.append(loss.data)
    test_acc.append(check(out, labels))

    for x in out:
      pred.append(x.argmax().cpu().data.numpy())
    for x in labels:
      true.append(x.cpu().data.numpy())

  avg_loss = sum(test_loss) / len(test_loss)
  avg_acc = sum(test_acc) / len(test_acc)

  print(f'Test Loss: {avg_loss} Test Accuracy: {avg_acc}')

  return pred, true

import math
from torch.nn import TransformerEncoder, TransformerEncoderLayer

class PositionalEncoding(nn.Module):

    def __init__(self, d_model, dropout=0.1, max_len=50):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(p=dropout)

        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)[:,:-1]
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)

    def forward(self, x):
        x = x + self.pe[:x.size(0), :]
        return self.dropout(x)

class TransformerClassifier(nn.Module):

  def __init__(self, nclasses = 3, ndim = 147, nheads = 7, nhid = 512, nlayers = 3, dropout = 0.4):

    super(TransformerClassifier, self).__init__()
    encoder_layer = TransformerEncoderLayer(ndim, nheads, nhid)
    self.encoder = TransformerEncoder(encoder_layer, nlayers)
    self.positional = PositionalEncoding(ndim)
    self.src_mask = None
    self.ndim = ndim
    self.fc = nn.Linear(ndim, nclasses)

  def _generate_src_mask(self, sz):

    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1).to(device)
    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))
    return mask

  def reduced_sum(self,out):

    size = out.shape
    final_out = torch.zeros(size[0],size[2]).to(device)
    for i in range(size[0]):
      final_out[i,0] = torch.sum(out[i,:,0])
      final_out[i,1] = torch.sum(out[i,:,1])
      final_out[i,2] = torch.sum(out[i,:,2])
    return final_out/size[1]


  def forward(self, input):

    input = input.permute(1,0,2)
    if self.src_mask is None or self.src_mask.size(0) != len(input):
      mask = self._generate_src_mask(len(input))
      self.src_mask = mask

    positonal = self.positional(input)
    out = self.encoder(positonal, self.src_mask)
    out = (out + input)
    out = out.permute(1,0,2)
    out = self.fc(out)
    out = F.softmax(self.reduced_sum(out),dim = 1)
    return out

model = TransformerClassifier().double().to(device)

model = TrainModel(model, train_dataloader, valid_dataloader, num_epochs= 100, learning_rate = 1e-6)

pred = TestModel(model, test_dataloader)

from sklearn.metrics import confusion_matrix
c_m = confusion_matrix(pred[1], pred[0])

import seaborn as sns
import matplotlib.pyplot as plt

df_cm = pd.DataFrame(c_m, index = ['N','C','U'],
                  columns = ['N','C','U'])
plt.figure(figsize = (6,5))
sns.heatmap(df_cm, cmap = 'Greens',annot=True)
plt.xlabel('Predicted')
plt.ylabel('True Value')

torch.save(model.state_dict(),'/content/sample_data/model.pt')

PATH = '/content/drive/My Drive/Pre-Trained Weights/IITH-transformer_classifier-90%.pt'
model.load_state_dict(torch.load(PATH))
#model.eval()

from fastai import *
import fastai.basic_data as basic_data

import fastai.basic_train as basic_train

databunch = basic_data.DataBunch(train_dl =  train_dataloader,
                                 valid_dl = valid_dataloader)

learner = basic_train.Learner(databunch, model, opt_func=torch.optim.Adam(model.parameters()), loss_func = nn.CrossEntropyLoss())

type(learner)

lr_find(learn:Learner, start_lr:Floats=1e-07, end_lr:Floats=10, num_it:int=100, stop_div:bool=True, wd:float=None)